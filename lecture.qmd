---
title: "Linear, Risk, Odds"
format: html
---


# Goals

- Linear Regression:
  - Prediction vs Causality
  - Prediction vs Fitting
  - Application of this technique in real life.
- Risk vs Odds
- Risk Ratio vs Odds Ratio

Check-in with where we are at:

```{r}
#| fig-align: center
include_graphics("includes/data-science.png")
```



# Setup

This week's data consists of data sets we have seen before.

```{r}
#| label: setup
#| echo: false
#| warning: false

library(cowplot)
library(knitr)
library(janitor)
library(rio)
library(tidymodels)
library(tidyverse)

appointments <- read_csv("data/Appointments.csv") |> clean_names()
insurance <- read_csv("data/insurance.csv")
```



# Insurance


## Data

```{r}
insurance |> head()
```

## Data Dictionary

- age: age of primary beneficiary
- sex: insurance contractor gender, female, male
- bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,
objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9
- children: Number of children covered by health insurance / Number of dependents
- smoker: Smoking
- region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.
- charges: Individual medical costs billed by health insurance

Data Source: [https://www.kaggle.com/datasets/mirichoi0218/insurance](https://www.kaggle.com/datasets/mirichoi0218/insurance)

## Linear Regression - Insurance Claims

Does this look familiar?

```{r}
ggplot(insurance, aes(x = age, y = charges, color = smoker)) +
  geom_point() +
  labs(x = "Age", y = "Charges") +
  theme_minimal_grid()
```

- It should, we worked with this insurance data several weeks ago.
- As we age, health insurance costs increase.
- Regardless of age, average costs for smokers is higher than non-smokers.
- This plot suggests this can predict charges using age and smoker status.

```{r}
lm_age_smoker <-
  linear_reg() |>
  fit(charges ~ age * smoker, data = insurance)
tidy(lm_age_smoker)
```

```{r}
glance(lm_age_smoker) |> head()
```

- The intercept for smokers is more than $20,000 higher than non-smokers.
  - The intercept tells us the predicted value of y where x equals 0.
  - Of course, nobody (alive) is exactly 0 years old.
  - But it also tells us that on average, smokers cost $22,000 more than non-smokers, regardless of age.
- Of course, there are many factors which affect cost which aren't in this model, so it has a pretty high standard error (sigma) of over $6,000.
  - Look at the plot to see why.

```{r}
ggplot(insurance, aes(x = age, y = charges, color = smoker)) +
  geom_point() +
  geom_smooth(method = lm) +
  labs(x = "Age", y = "Charges") +
  theme_minimal_grid()
```

- For non-smokers, we have some outliers which pull the non-smoker average up.
- For smokers, we have two bands and our model's fitted values are almost perfectly in-between.
- To improve this model:
  - Assess if the outliers are correct. If they aren't, consider removing them. If they are, what explains them?
  - What explains the two different cost bands for smokers?
  - Banding in a linear regression suggests there is either an error in the data (measurement error) or there is a categorical variable which could explain what is going on.
  - Note: I keep saying explain, not cause. Depending on WHY you are modeling something, you may or may not care about causality.

## Predicting

Let's say I have some new data:

```{r}
# I will create a new tibble from two vectors of data.
# This data does NOT contain any charges data, that is what I want to predict.
new_charges <- tibble(
  age = c(28, 31, 47, 63),
  smoker = c('yes', 'no', 'yes', 'no')
  )
new_charges
```

So, given this new data, how can I predict charges for these people?

```{r}
new_charges <-
  lm_age_smoker |>
  augment(new_data = new_charges)
new_charges
```

Note that last week when we used augment, we got TWO columns:

- .pred
- .residual

But because we don't have any actual charges data, we cannot calculate the residuals. All we have is the predicted values.

And we can see how this would fall onto our previous plot.

```{r}
ggplot(insurance, aes(x = age, y = charges, color = smoker)) +
  geom_point() +
  geom_smooth(method = lm) +
  geom_point(
    data = new_charges,
    aes(x = age, y = .pred),
    shape = 18, size = 5, color = "black"
  ) +
  labs(x = "Age", y = "Charges", title = "Predicted values overlaid original data") +
  theme_minimal_grid()
```

And while this model is relatively simple, this is as real as it gets: Hierarchical Condition Categories (HCC)

- HCC: A hierarchical model used to predict Medicare and non-Medicare patient costs.
- Developed by the Centers for Medicare and Medicaid Services (CMS).
- Hierarchical models (aka multilevel models) go beyond the scope of this class, but is a generalization of Ordinary Least Squares regression (linear).
- The model includes variables (features) such as age and gender.
  - Older patients are generally more expensive than their younger peers.
- Also includes variables for disease diagnosis such as cancer, congestive heart failure (CHF), COPD, chronic kidney disease (CKD), etc.
  - These variables are all true/false. You either have COPD or you do not.
  - Progressive diseases such as CKD are handled by multiple variables (CKD 1, CKD 2, etc.)
  - Each additional diagnosis adds to the expected patient cost.



# Risk vs Odds

- Do you remember the appointments data set from the midterm?
  - I am sympathetic if you chose to block it out.

## Data

```{r}
appointments |> head()
```

## Data Dictionary

  - patient_id: Unique identifier for that patient.
  - appointment_id: Unique identifier for each appointment
  - gender: Male (M) or Female (F).
  - appointment_date: The Date (YYYY-MM-DD) of the appointment
  - appointment_day: An abbreviation of the name of the day of the
    appointment (Mon, Tue, etc.)
  - appointment_month: The abbreviation of the name of the month of the
    appointment.
  - age: Patient age, on the day of the appointment, in years.
  - neighbourhood: Where the appointment takes place.
    - Note the unusual spelling of this column name.
  - scholarship: TRUE or FALSE
      - For more detail:
        <https://en.wikipedia.org/wiki/Bolsa_Fam%C3%ADlia>
  - hipertension: Does the patient have hypertension? TRUE or FALSE
      - Note the unusual spelling of this column name.
  - diabetes: Does the patient have diabetes? TRUE or FALSE
  - alcoholism: Does the patient have diabetes? TRUE or FALSE
  - handcap: Does the patient have a handicap? TRUE or FALSE
      - Note the unusual spelling of this column name.
      - This is not my typo.
  - received_sms: Did the patient receive a SMS? TRUE or FALSE
  - no_show: Did the patient no-show? TRUE or FALSE
  
## Percent No Show

- What percentage of appointments no-show?
- This should feel REAL familiar.

```{r}
# Two paths, one destination:

appointments |>
  summarize(
    den = n(),
    num = sum(no_show),
    p = 100*num/den
  )

appointments |>
  summarize(
    den = n(),
    num = sum(no_show)
  ) |>
  mutate(
    p = round(100*num/den,1)
  )
```

Calculating a rate requires a numerator and a denominator. To calculate the percentage of appointments which no-show takes three steps:

1. Denominator (den): Total number of appointments.
2. Numerator (num): Number of no-shows appointments.
3. Percentage (p): $100 * (Numerator/Denominator)$

All three of these steps can take place in a single summarize command or you can calculate the percentage in a separate mutate function as shown above.

## Risk No Show

Now calculate the over-all RISK of having a no-show appointment.

```{r}
appointments |>
  summarize(
    den = n(),
    num = sum(no_show),
    risk = 100*num/den
  )
```

- Risk is the measure of the likelihood of a particular outcome you are most likely familiar with.
  - The only difference between a percentage calculation and a risk calculation is the label.
- More formally: The ratio of the number of events that produce the outcome of interest to the total number of events.
  - You don't have to multiply by 100. We often do, but it isn't required.
  - But you do want to be clear if you have or not.
  - In other words: .202 risk is the same as 20.2% risk. Just make sure your audience knows if you are using the raw risk or the percent risk.

## Odds No Show 

- The odds of a no-show are a related concept.
- Odds provide another measure of the likelihood of a particular outcome.
- The ratio of the number of events that produce the outcome of interest to the number that do not. 

```{r}
# These two methods are functionally equivalent.

appointments |>
  summarize(
    den = n() - sum(no_show),
    num = sum(no_show),
    odds = num/den
  )

# OR

appointments |>
  summarize(
    den = sum(!no_show),
    num = sum(no_show),
    odds = num/den
  )
```

- Unlike risk, never multiply odds by 100.
- Odds are often written as a fraction or ratio.
  - In this example, the odds are _approximately_ 1 to 4.
  - Read as: For every one no-show, you would expect four arrived appointments.
  - For rare events, the odds and the risk are very similar.
    - See below for a demo of how the risk roughly equals odds for adequately rare events.
  - When expressed as a decimal, the odds tend to "over-dramatize" likelihood of an event because we more naturally think in terms of risk than odds.   

Comparing Hypothetical Odds to Risk:

| No Show | Arrived | Appointments |  Risk |  Odds |
|--------:|--------:|-------------:|------:|------:|
|      20 |      80 |          100 | .2000 | .2500 |
|      20 |     800 |          820 | .0240 | .0250 |
|      20 |    8000 |         8020 | .0020 | .0025 | 

- The above table contains the actual risk, not the percent.
- This makes it easier to compare to the odds.
- As the risk of no-show decreases, risk and odds become basically identical.
- We will expand on the utility of this next week when we introduce logistic regression.



# Risk Ratio vs Odds Ratio

- Sometimes we want to compare the risk of two groups.
- For example, compare the risk of a no-show when the patient received a SMS reminder to the risk of a no-show when the patient did not receive a SMS reminder.

```{r}
# I will save my calculated results to risk_sms for the next step.
# I do not calculate percent risk here.
risk_sms <- 
  appointments |>
  group_by(received_sms) |>
  summarize(
    den = n(),
    num = sum(no_show),
    risk = num/den
  )
risk_sms
```

- Appointments where the patient received a SMS message have a higher risk (percentage) of no-show appointments than appointments where the patient did not receive a SMS reminder.
- But how can we compare these risk levels?

RISK RATIO

To calculate a risk ratio: Divide the risk of the higher risk group by the risk of the lower risk group. You want a fraction GREATER than 1.

```{r}
# Calculating Relative Risk
# Two paths to the same destination.

risk_sms |>
  summarize(
    risk_ratio = risk[received_sms] / risk[!received_sms]
  )

risk_sms |>
  summarize(
    risk_ratio = risk[received_sms == TRUE] / risk[received_sms == FALSE]
  )
```

- Let's talk about that funky "square bracket" notation.
- You may recall that I told you, in passing, that a dataframe/tibble uses a vector as a column.
  - And then I never told you what a vector was again.
  - A vector is just a collection of information with the same data type.

```{r}
foo <- c(1, 2, 3, 4)
bar <- c(TRUE, FALSE, TRUE, FALSE)
foo
bar
```

Here, I have created TWO vectors, foo and bar. And we can operate on these.

```{r}
sum(foo)
```

```{r}
sum(bar)
```

And we can perform filtering operations using SQUARE BRACKET NOTATION.

```{r}
foo[bar == TRUE]
```

OR

```{r}
bar[foo < 3]
```

We rarely need to use square bracket notation when using the tidyverse functions, but I have never found another way to calculate risk and odds ratios.

Speaking of risk, let's calculate the Odds Ratio of no-show.

```{r}
appointments |>
  group_by(received_sms) |>
  summarize(
    den = sum(!no_show),
    num = sum(no_show),
    odds = num/den
  ) |>
  summarize(
    odds_ratio = odds[received_sms]/odds[!received_sms]
  )
```

- Because no-show is not rare, the odds ratio is more dramatic than the risk ratio.
- It isn't wrong, we just don't easily think about things this way.
- Thus, it can be misleading.
- And next week I will explain why we did all of this.